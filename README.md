# Out of the Box Education Classification

This is some of my efforts to classify spending in the DrivenData competition.  

1. Within the PolishedPresentation folder the file *ExpenditureClassification.R* chooses words from each of the explanatory variables with high tf-idfs in a combined document for each classification within each category and creates a feature file for each line item in the train data set according as that word appears in the appropriate variable for that word.

2. These features were then used to generate random forest models.  Since this proceeded too slowly on my computer in R, the models were done instead in python.  *GenerateRandomForestModels.py* generated the models and *GenerateSubmissionRandomForest.py* was used to make predictions on the test data.

3.  The first attempt to improve on this model began with the **Function** category which had the lowest accuracy of the models.  Examination of a crosstable showed that too many instances were being placed in the **Teacher Compensation** class and words were chosen which might best separate this category with it's most frequent confounders.  These efforts are recorded in the file *ExploreTeacherCompensation.R*. 

4.  This inspired a reexamination of all the categories.  The general structure is that each attempt is contained in a folder of type Refine[Cat] where an R file *Update[Cat]Features.r* finds additional words and adds these features to the train and test data sets.  Random forests are generated by *GenerateRandomForestModel.py* files and used to generate preditions in *ClassifyIn[Cat].py* files.

5. ExploreMetric contains attempts to explore how to convert the random forest models whose splits are based on Gini index into probability estimates less abused by the log loss metric used by the competition.